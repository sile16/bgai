{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sile16/bgai/blob/main/bg_training_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t09halfxry1M"
   },
   "source": [
    "# Hello World, TurboZero Backgammon üèÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfStBtc8l_ke",
    "outputId": "ba96af27-11be-4ac9-9704-3508849357d7"
   },
   "outputs": [],
   "source": [
    "# prompt: ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/tmp/pgx'\n",
    "\n",
    "#%pip install --upgrade pip\n",
    "#%pip install -U git+https://github.com/sile16/pgx.git@master\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yB3nZpVwvtwn",
    "outputId": "2b84d7e0-4415-4a24-a205-628ee10f1e35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGX Version 2.5.10\n"
     ]
    }
   ],
   "source": [
    "import pgx\n",
    "print(f\"PGX Version {pgx.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IHbqqCYlpJUG",
    "outputId": "bbf27ade-8895-4272-c7aa-7e98ba7bb003"
   },
   "outputs": [],
   "source": [
    "#%pip install git+https://github.com/sile16/turbozero.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "8jOXiravr9u2",
    "outputId": "52b2399d-71d6-41e1-f6fb-b2d8cac615f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax Version:  0.6.2\n",
      "Default backend: gpu\n",
      "Jax Version 0.6.2\n",
      "False\n",
      "156\n",
      "[0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n",
      " 0.05555556 0.05555556 0.05555556]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg baseProfile=\"full\" height=\"375.0\" version=\"1.1\" width=\"450.0\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><rect fill=\"white\" height=\"425\" width=\"575\" x=\"0\" y=\"0\" /><g transform=\"scale(1.0)\"><rect fill=\"white\" height=\"375\" width=\"450\" x=\"0\" y=\"0\" /><g transform=\"translate(12.5,12.5)\"><polygon fill=\"white\" points=\"0,0 25,0 12.5,150\" stroke=\"gray\" /><polygon fill=\"gray\" points=\"25,0 50,0 37.5,150\" stroke=\"gray\" /><polygon fill=\"white\" points=\"50,0 75,0 62.5,150\" stroke=\"gray\" /><polygon fill=\"gray\" points=\"75,0 100,0 87.5,150\" stroke=\"gray\" /><polygon fill=\"white\" points=\"100,0 125,0 112.5,150\" stroke=\"gray\" /><polygon fill=\"gray\" points=\"125,0 150,0 137.5,150\" stroke=\"gray\" /><polygon fill=\"white\" points=\"175,0 200,0 187.5,150\" stroke=\"gray\" /><polygon fill=\"gray\" points=\"200,0 225,0 212.5,150\" stroke=\"gray\" /><polygon fill=\"white\" points=\"225,0 250,0 237.5,150\" stroke=\"gray\" /><polygon fill=\"gray\" points=\"250,0 275,0 262.5,150\" stroke=\"gray\" /><polygon fill=\"white\" points=\"275,0 300,0 287.5,150\" stroke=\"gray\" /><polygon fill=\"gray\" points=\"300,0 325,0 312.5,150\" stroke=\"gray\" /><polygon fill=\"gray\" points=\"0,350 25,350 12.5,200\" stroke=\"gray\" /><polygon fill=\"white\" points=\"25,350 50,350 37.5,200\" stroke=\"gray\" /><polygon fill=\"gray\" points=\"50,350 75,350 62.5,200\" stroke=\"gray\" /><polygon fill=\"white\" points=\"75,350 100,350 87.5,200\" stroke=\"gray\" /><polygon fill=\"gray\" points=\"100,350 125,350 112.5,200\" stroke=\"gray\" /><polygon fill=\"white\" points=\"125,350 150,350 137.5,200\" stroke=\"gray\" /><polygon fill=\"gray\" points=\"175,350 200,350 187.5,200\" stroke=\"gray\" /><polygon fill=\"white\" points=\"200,350 225,350 212.5,200\" stroke=\"gray\" /><polygon fill=\"gray\" points=\"225,350 250,350 237.5,200\" stroke=\"gray\" /><polygon fill=\"white\" points=\"250,350 275,350 262.5,200\" stroke=\"gray\" /><polygon fill=\"gray\" points=\"275,350 300,350 287.5,200\" stroke=\"gray\" /><polygon fill=\"white\" points=\"300,350 325,350 312.5,200\" stroke=\"gray\" /><rect fill=\"none\" height=\"350\" stroke=\"black\" width=\"325\" x=\"0\" y=\"0\" /><rect fill=\"none\" height=\"350\" stroke=\"black\" width=\"25\" x=\"150\" y=\"0\" /><circle cx=\"287.5\" cy=\"337.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"262.5\" cy=\"337.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"262.5\" cy=\"312.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"262.5\" cy=\"287.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"212.5\" cy=\"337.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"212.5\" cy=\"312.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"187.5\" cy=\"337.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"187.5\" cy=\"312.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"187.5\" cy=\"287.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"112.5\" cy=\"337.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"112.5\" cy=\"312.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"112.5\" cy=\"287.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"87.5\" cy=\"337.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"87.5\" cy=\"312.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"12.5\" cy=\"337.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"12.5\" cy=\"12.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"87.5\" cy=\"12.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"87.5\" cy=\"37.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"112.5\" cy=\"12.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"112.5\" cy=\"37.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"112.5\" cy=\"62.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"187.5\" cy=\"12.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"187.5\" cy=\"37.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"187.5\" cy=\"62.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"212.5\" cy=\"12.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"212.5\" cy=\"37.5\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><circle cx=\"262.5\" cy=\"12.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"262.5\" cy=\"37.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"262.5\" cy=\"62.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><circle cx=\"287.5\" cy=\"12.5\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><rect fill=\"white\" height=\"50\" stroke=\"black\" width=\"100\" x=\"325\" y=\"0\" /><circle cx=\"350\" cy=\"25\" fill=\"black\" r=\"12.5\" stroke=\"black\" /><text fill=\"black\" font-family=\"serif\" font-size=\"34px\" x=\"365.0\" y=\"35.0\">√ó0</text><rect fill=\"white\" height=\"50\" stroke=\"black\" width=\"100\" x=\"325\" y=\"300\" /><circle cx=\"350\" cy=\"325\" fill=\"white\" r=\"12.5\" stroke=\"black\" /><text fill=\"black\" font-family=\"serif\" font-size=\"34px\" x=\"365.0\" y=\"335.0\">√ó0</text><text fill=\"black\" font-family=\"sans serif\" font-size=\"44px\" x=\"337.5\" y=\"187.5\">‚öÄ</text><text fill=\"black\" font-family=\"sans serif\" font-size=\"44px\" x=\"370.0\" y=\"187.5\">‚öÉ</text></g></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jax\n",
    "print(\"Jax Version: \",jax.__version__)\n",
    "#jax.config.update('jax_platform_name', 'gpu')\n",
    "from jax.lib import xla_bridge\n",
    "from prompt_toolkit import HTML\n",
    "print(\"Default backend:\", jax.default_backend())\n",
    "\n",
    "import pgx\n",
    "import pgx.backgammon as bg\n",
    "\n",
    "print(f\"Jax Version {jax.__version__}\")\n",
    "\n",
    "\n",
    "env = bg.Backgammon(short_game=True)\n",
    "print(env.simple_doubles)\n",
    "print(env.num_actions)\n",
    "print(env.stochastic_action_probs)\n",
    "\n",
    "# create key\n",
    "key = jax.random.PRNGKey(0)\n",
    "state = env.init(key)\n",
    "from IPython.display import HTML\n",
    "display(HTML(state.to_svg()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7W7bQsPGryIc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uh-PeXqD238R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@chex.dataclass(frozen=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
       "\u001b[38;5;28;01mclass\u001b[39;00m StepMetadata:\n",
       "    \u001b[33m\"\"\"Metadata for a step in the environment.\u001b[39m\n",
       "\u001b[33m    - `rewards`: rewards received by the players\u001b[39m\n",
       "\u001b[33m    - `action_mask`: mask of valid actions\u001b[39m\n",
       "\u001b[33m    - `terminated`: whether the environment is terminated\u001b[39m\n",
       "\u001b[33m    - `cur_player_id`: current player id\u001b[39m\n",
       "\u001b[33m    - `step`: step number\u001b[39m\n",
       "\u001b[33m    \"\"\"\u001b[39m\n",
       "    rewards: chex.Array\n",
       "    action_mask: chex.Array\n",
       "    terminated: bool\n",
       "    cur_player_id: int\n",
       "    step: int\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from core.types import StepMetadata\n",
    "%psource StepMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sUQbfbgh24SM"
   },
   "outputs": [],
   "source": [
    "import chex\n",
    "from typing import Tuple\n",
    "\n",
    "def step_fn(state: bg.State, action: int, key: chex.PRNGKey) -> Tuple[bg.State, StepMetadata]:\n",
    "    \"\"\"Combined step function for backgammon environment that handles both deterministic and stochastic actions.\"\"\"\n",
    "    # print(f\"[DEBUG-BG_STEP-{time.time()}] Called with state (stochastic={state._is_stochastic}), action={action}\") # Optional debug\n",
    "\n",
    "    # Handle stochastic vs deterministic branches\n",
    "    def stochastic_branch(operand):\n",
    "        s, a, _ = operand # state, action, key (key ignored for stochastic step)\n",
    "        # Use env instance captured by closure (assuming env is accessible in this scope)\n",
    "        return env.stochastic_step(s, a)\n",
    "\n",
    "    def deterministic_branch(operand):\n",
    "        s, a, k = operand # state, action, key\n",
    "        # Use env instance captured by closure\n",
    "        return env.step(s, a, k)\n",
    "\n",
    "    # Use conditional to route to the appropriate branch\n",
    "    # The key is only needed for the deterministic branch\n",
    "    new_state = jax.lax.cond(\n",
    "        state._is_stochastic,\n",
    "        stochastic_branch,\n",
    "        deterministic_branch,\n",
    "        (state, action, key) # Pass all required operands\n",
    "    )\n",
    "\n",
    "    # Create standard metadata\n",
    "    metadata = StepMetadata(\n",
    "        rewards=new_state.rewards,\n",
    "        action_mask=new_state.legal_action_mask,\n",
    "        terminated=new_state.terminated,\n",
    "        cur_player_id=new_state.current_player,\n",
    "        step=new_state._step_count\n",
    "    )\n",
    "\n",
    "    return new_state, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5uCAYJjP2-7J"
   },
   "outputs": [],
   "source": [
    "def init_fn(key):\n",
    "    \"\"\"Initializes a new environment state.\"\"\"\n",
    "    state = env.init(key)\n",
    "    # No need to force non-stochastic, let the environment handle it\n",
    "    return state, StepMetadata(\n",
    "        rewards=state.rewards,\n",
    "        action_mask=state.legal_action_mask,\n",
    "        terminated=state.terminated,\n",
    "        cur_player_id=state.current_player,\n",
    "        step=state._step_count\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHQOdA793BxX"
   },
   "outputs": [],
   "source": "import jax\nimport jax.numpy as jnp\nimport flax.linen as nn\n\n# Define a dense residual block for vector inputs.\nclass ResidualDenseBlock(nn.Module):\n    features: int\n\n    @nn.compact\n    def __call__(self, x):\n        residual = x\n        x = nn.Dense(self.features)(x)\n        x = nn.LayerNorm()(x)\n        x = nn.relu(x)\n        x = nn.Dense(self.features)(x)\n        x = nn.LayerNorm()(x)\n        return nn.relu(x + residual)\n\n# Updated ResNet-style network with 6-way value head for backgammon outcomes.\nclass ResNetTurboZero(nn.Module):\n    \"\"\"ResNet-style network with 6-way value head for backgammon outcomes.\n    \n    Value head outputs logits for 6 outcomes:\n    [win, gammon_win, backgammon_win, loss, gammon_loss, backgammon_loss]\n    \"\"\"\n    num_actions: int       # e.g. 156 for backgammon\n    num_hidden: int = 256  # Hidden layer dimension (increased from 128)\n    num_blocks: int = 6    # Number of residual blocks (increased from 2)\n    value_head_out_size: int = 6  # 6-way outcome distribution\n\n    @nn.compact\n    def __call__(self, x, train: bool = False):\n        # Initial projection.\n        x = nn.Dense(self.num_hidden)(x)\n        x = nn.LayerNorm()(x)\n        x = nn.relu(x)\n\n        # Process through a series of residual blocks.\n        for _ in range(self.num_blocks):\n            x = ResidualDenseBlock(self.num_hidden)(x)\n\n        # Policy head: project features to logits over possible actions.\n        policy_logits = nn.Dense(self.num_actions)(x)\n\n        # 6-way value head: outputs logits, converted to probs by loss fn.\n        value_logits = nn.Dense(self.value_head_out_size)(x)\n        return policy_logits, value_logits\n\n\n# Larger model for better learning capacity\nresnet_model = ResNetTurboZero(env.num_actions, num_hidden=256, num_blocks=6)"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Jrk63m3f3IWK"
   },
   "outputs": [],
   "source": [
    "def state_to_nn_input(state):\n",
    "    return state.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-I5lO_x03Pfc"
   },
   "outputs": [],
   "source": [
    "from core.evaluators.evaluation_fns import make_nn_eval_fn\n",
    "from core.evaluators.mcts.action_selection import PUCTSelector\n",
    "from core.evaluators.mcts.stochastic_mcts import StochasticMCTS\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Training evaluator: StochasticMCTS using NN\n",
    "# Reduced iterations for faster collection (was 300, now 100)\n",
    "evaluator = StochasticMCTS(\n",
    "    eval_fn=make_nn_eval_fn(resnet_model, state_to_nn_input),\n",
    "    stochastic_action_probs=env.stochastic_action_probs,\n",
    "    num_iterations=100,  # Reduced from 300 for faster collection\n",
    "    max_nodes=400,       # Reduced from 500\n",
    "    branching_factor=env.num_actions,\n",
    "    action_selector=PUCTSelector(),\n",
    "    temperature=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aWZzaWvR3WoJ"
   },
   "outputs": [],
   "source": [
    "# Test evaluator: more iterations for better evaluation quality\n",
    "evaluator_test = StochasticMCTS(\n",
    "    eval_fn=make_nn_eval_fn(resnet_model, state_to_nn_input),\n",
    "    stochastic_action_probs=env.stochastic_action_probs,\n",
    "    num_iterations=100,  # More iterations for testing\n",
    "    max_nodes=400,\n",
    "    branching_factor=env.num_actions,\n",
    "    action_selector=PUCTSelector(),\n",
    "    temperature=0.0,  # Greedy for testing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzo8mbXp3bKM"
   },
   "outputs": [],
   "source": "from core.evaluators.evaluation_fns import make_nn_eval_fn_no_params_callable\nimport chex\nimport sys\nfrom pathlib import Path\n\n# Add bgai to path (parent directory of notebooks)\nbgai_root = Path().resolve().parent\nif str(bgai_root) not in sys.path:\n    sys.path.insert(0, str(bgai_root))\n\n# --- Import pip count eval from bgai (now returns 6-way value logits) ---\nfrom bgai.bgevaluators import backgammon_pip_count_eval\n\n\n# Test evaluator: Regular MCTS using pip count\npip_count_mcts_evaluator_test = StochasticMCTS(  # optimizes for moves\n    eval_fn=backgammon_pip_count_eval, # Use pip count eval fn (now returns 6-way logits)\n    stochastic_action_probs=env.stochastic_action_probs,\n    num_iterations=100, # Give it slightly more iterations maybe\n    max_nodes=200,\n    branching_factor=env.num_actions,\n    action_selector=PUCTSelector(),\n    temperature=0.0 # Deterministic action selection for testing\n)\n\n# --- GnuBG Evaluator (for testing against strong baseline) ---\nfrom bgai.gnubg_evaluator import GnubgEvaluator\n\ngnubg_evaluator = GnubgEvaluator(env=env)"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cUwy12-l3ekK"
   },
   "outputs": [],
   "source": [
    "from core.memory.replay_memory import EpisodeReplayBuffer\n",
    "\n",
    "# Larger replay buffer for more diverse training data\n",
    "replay_memory = EpisodeReplayBuffer(capacity=4000)  # Increased from 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YY9U4XuS4JjI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0YilslD4XDw"
   },
   "source": [
    "## Trainer Initialization\n",
    "Now that we have all the proper pieces defined, we are ready to initialize a Trainer and start training!\n",
    "\n",
    "The `Trainer` takes many parameters, so let's walk through them all:\n",
    "* `batch_size`: # of parallel environments used to collect self-play games\n",
    "* `train_batch_size`: size of minibatch used during training step\n",
    "* `warmup_steps`: # of steps (per batch) to collect via self-play prior to entering the training loop. This is used to populate the replay memory with some initial samples\n",
    "* `collection_steps_per_epoch`: # of steps (per batch) to collect via self-play per epoch\n",
    "* `train_steps_per_epoch`: # of train steps per epoch\n",
    "* `nn`: neural network (`linen.Module`)\n",
    "* `loss_fn`: loss function used for training, we use a provided default loss which implements the loss function used in the `AlphaZero` paper\n",
    "* `optimizer`: an `optax` optimizer used for training\n",
    "* `evaluator`: the `Evaluator` to use during self-play, we initialized ours using `AlphaZero(MCTS)`\n",
    "* `memory_buffer`: the memory buffer used to store samples from self-play games, we  initialized ours using `EpisodeReplayBuffer`\n",
    "* `max_episode_steps`: maximum number of steps/turns to allow before truncating an episode\n",
    "* `env_step_fn`: environment step function (we defined ours above)\n",
    "* `env_init_fn`: environment init function (we defined ours above)\n",
    "* `state_to_nn_input_fn`: function to convert environment state to nn input (we defined ours above)\n",
    "* `testers`: any number of `Tester`s, used to evaluate a given model and take their own parameters. We'll use the two evaluators defined above to initialize two Testers.\n",
    "* `evaluator_test`: (Optional) Evaluator used within Testers. By default used `evaluator`, but sometimes you may want to test with a larger MCTS iteration budget for example, or a different move sampling temperature\n",
    "* `data_transform_fns`: (optional) list of data transform functions to apply to self-play experiences (e.g. rotation, reflection, etc.)\n",
    "* `extract_model_params_fn`: (Optional) in special cases we need to define how to extract all model parameters from a flax `TrainState`. The default function handles BatchNorm, but if another special-case technique applied across batches is used (e.g. Dropout) we would need to define a function to extract the appropriate parameters. You usually won't need to define this!\n",
    "* `wandb_project_name`: (Optional) Weights and Biases project name. You will be prompted to login if a name is provided. If a name is provided, a run will be initialized and loss and other metrics will be logged to the given wandb project.\n",
    "* `ckpt_dir`: (Optional) directory to store checkpoints in, by default this is set to `/tmp/turbozero_checkpoints`\n",
    "* `max_checkpoints`: (Optional) maximum number of most-recent checkpoints to retain (default: 2)\n",
    "* `num_devices`: (Optional) number of hardware accelerators (GPUs/TPUs) to use. If not given, all available hardware accelerators are used\n",
    "* `wandb_run`: (Optional) continues from an initialized `wandb` run if provided, otherwise a new one is initialized\n",
    "* `extra_wandb_config`: (Optional) any extra metadata to store in the `wandb` run config\n",
    "\n",
    "A training epoch is comprised of M collection steps, followed by N training steps sampling minibatches from replay memory. Optionally, any number of Testers evaluate the current model. At the end of each epoch, a checkpoint is saved.\n",
    "\n",
    "If you are using one or more GPUs (reccommended), TurboZero by default will run on all your available hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "s5lIK8kf4YAe",
    "outputId": "2ea3d0a9-8246-4739-8b03-9975c140540c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msile16\u001b[0m (\u001b[33msile16-self\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from core.testing.two_player_baseline import TwoPlayerBaseline\n",
    "from core.training.loss_fns import az_default_loss_fn\n",
    "from core.training.stochastic_train import StochasticTrainer\n",
    "from core.training.train import Trainer\n",
    "import optax\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING CONFIGURATION FOR RTX 4090 - 20 EPOCHS (~6-12 hours)\n",
    "# =============================================================================\n",
    "# Key changes from original:\n",
    "# - batch_size: 64 -> 256 (more parallelism, 4090 has 24GB)\n",
    "# - train_batch_size: 32 -> 128 (better GPU utilization)\n",
    "# - collection_steps_per_epoch: 2048 -> 4096 (more data per epoch)\n",
    "# - train_steps_per_epoch: 1024 -> 2048 (more training per epoch)\n",
    "# - MCTS iterations: 300 -> 100 (faster collection, still good policy)\n",
    "# - Neural net: 2 blocks -> 6 blocks, 128 -> 256 hidden (more capacity)\n",
    "# - Replay buffer: 2000 -> 4000 (more diversity)\n",
    "# - Temperature decay: 1.0 -> 0.2 over training (exploration -> exploitation)\n",
    "# =============================================================================\n",
    "\n",
    "trainer = StochasticTrainer(\n",
    "    batch_size=256,                   # Increased from 64 (4090 can handle it)\n",
    "    train_batch_size=128,             # Increased from 32\n",
    "    warmup_steps=0,\n",
    "    collection_steps_per_epoch=4096,  # Increased from 2048\n",
    "    train_steps_per_epoch=2048,       # Increased from 1024\n",
    "    nn=resnet_model,\n",
    "    loss_fn=partial(az_default_loss_fn, l2_reg_lambda=1e-4),\n",
    "    optimizer=optax.adam(3e-4),       # Slightly higher LR for faster convergence\n",
    "    evaluator=evaluator,\n",
    "    memory_buffer=replay_memory,\n",
    "    max_episode_steps=500,            # Reduced from 1000 (games rarely go this long)\n",
    "    env_step_fn=step_fn,\n",
    "    env_init_fn=init_fn,\n",
    "    state_to_nn_input_fn=state_to_nn_input,\n",
    "    ckpt_dir=\"/tmp/ckpts\",\n",
    "    testers=[\n",
    "        TwoPlayerBaseline(\n",
    "            num_episodes=64,          # More episodes for reliable eval\n",
    "            baseline_evaluator=pip_count_mcts_evaluator_test,\n",
    "            name='pip_count_baseline'\n",
    "        ),\n",
    "        TwoPlayerBaseline(\n",
    "            num_episodes=16,          # Fewer episodes (gnubg is slower, not batched)\n",
    "            baseline_evaluator=gnubg_evaluator,\n",
    "            name='gnubg_baseline'\n",
    "        ),\n",
    "    ],\n",
    "    evaluator_test=evaluator_test,\n",
    "    data_transform_fns=[],\n",
    "    wandb_project_name=\"bgai-training\"  # Enable wandb logging\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# TEMPERATURE DECAY SCHEDULE\n",
    "# =============================================================================\n",
    "# Decay from 1.0 (exploration) to 0.2 (mostly exploitation) over training\n",
    "# This helps early training explore diverse moves, then focus on best moves later\n",
    "# =============================================================================\n",
    "NUM_EPOCHS = 20\n",
    "COLLECTION_STEPS_PER_EPOCH = 4096\n",
    "BATCH_SIZE = 256\n",
    "TOTAL_STEPS = NUM_EPOCHS * COLLECTION_STEPS_PER_EPOCH * BATCH_SIZE\n",
    "\n",
    "def temperature_schedule(step):\n",
    "    \"\"\"Linear decay from 1.0 to 0.2 over training.\"\"\"\n",
    "    start_temp = 1.0\n",
    "    end_temp = 0.2\n",
    "    progress = min(step / TOTAL_STEPS, 1.0)\n",
    "    return start_temp - (start_temp - end_temp) * progress\n",
    "\n",
    "trainer.set_temp_fn(temperature_schedule)\n",
    "print(f\"Temperature schedule: 1.0 -> 0.2 over {TOTAL_STEPS:,} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NKCXj6V4cQG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 15:59:31.798522: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-11-29 15:59:31.798564: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-11-29 15:59:31.798581: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-11-29 15:59:31.798604: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-11-29 15:59:31.798616: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-11-29 15:59:31.798631: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Done\n",
      "Epoch 0: {'grad_norm': '8.3523', 'loss': '2.4573', 'policy_accuracy': '0.4971', 'policy_loss': '1.1759', 'value_loss': '0.6902'}\n",
      "Testing\n",
      "Epoch 0: {'pip_count_baseline_avg_outcome': '-0.2188'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-2' coro=<_async_in_context.<locals>.run_in_context() done, defined at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-3' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "/home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/jax/_src/tree_util.py:362: RuntimeWarning: coroutine 'Kernel.shell_main' was never awaited\n",
      "  return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-3' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-4' coro=<_async_in_context.<locals>.run_in_context() done, defined at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-5' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-5' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-15' coro=<_async_in_context.<locals>.run_in_context() done, defined at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-16' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "/home/sile/.pyenv/versions/3.12.10/lib/python3.12/threading.py:1485: RuntimeWarning: coroutine 'Kernel.shell_main' was never awaited\n",
      "  def current_thread():\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-16' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-23' coro=<_async_in_context.<locals>.run_in_context() done, defined at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-24' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-24' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-10' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-11' coro=<_async_in_context.<locals>.run_in_context() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:60> wait_for=<Task pending name='Task-14' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "/home/sile/.pyenv/versions/3.12.10/lib/python3.12/_weakrefset.py:88: RuntimeWarning: coroutine 'Kernel.shell_main' was never awaited\n",
      "  self.data.add(ref(item, self._remove))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-6' coro=<_async_in_context.<locals>.run_in_context() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:60> wait_for=<Task pending name='Task-10' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-14' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-19' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-20' coro=<_async_in_context.<locals>.run_in_context() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:60> wait_for=<Task pending name='Task-22' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-17' coro=<_async_in_context.<locals>.run_in_context() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:60> wait_for=<Task pending name='Task-19' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-22' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-27' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-28' coro=<_async_in_context.<locals>.run_in_context() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:60> wait_for=<Task pending name='Task-29' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-25' coro=<_async_in_context.<locals>.run_in_context() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:60> wait_for=<Task pending name='Task-27' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-29' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: {'gnubg_baseline_avg_outcome': '0.6250'}\n",
      "Temperature: 0.96\n",
      "Collecting self-play games\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "ERROR:asyncio:Exception in callback Task.__step()\n",
      "handle: <Handle Task.__step()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sile/.pyenv/versions/3.12.10/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "RuntimeError: cannot enter context: <_contextvars.Context object at 0x7b852af31400> is already entered\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-981' coro=<_async_in_context.<locals>.run_in_context() done, defined at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:57> wait_for=<Task pending name='Task-982' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "/home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/jax/_src/tree_util.py:1139: RuntimeWarning: coroutine 'Kernel.shell_main' was never awaited\n",
      "  return default_registry.flatten_with_path(tree, is_leaf_with_kp)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-982' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Done\n",
      "Epoch 1: {'grad_norm': '5.5510', 'loss': '2.1993', 'policy_accuracy': '0.5562', 'policy_loss': '1.0733', 'value_loss': '0.6478'}\n",
      "Temperature: 0.9199999999999999\n",
      "Collecting self-play games\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-31' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-32' coro=<_async_in_context.<locals>.run_in_context() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:60> wait_for=<Task pending name='Task-980' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "Exception ignored in: <coroutine object Kernel.shell_main at 0x7b7c63484a40>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <lambda>\n",
      "KeyError: '__import__'\n",
      "Exception ignored in: <coroutine object Kernel.shell_main at 0x7b7c63484a40>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <lambda>\n",
      "KeyError: '__import__'\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-30' coro=<_async_in_context.<locals>.run_in_context() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/utils.py:60> wait_for=<Task pending name='Task-31' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]> cb=[ZMQStream._run_callback.<locals>._log_error() at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py:563]>\n",
      "Exception ignored in: <coroutine object Kernel.shell_main at 0x7b7c63432440>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <lambda>\n",
      "KeyError: '__import__'\n",
      "ERROR:asyncio:Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-980' coro=<Kernel.shell_main() running at /home/sile/.pyenv/versions/3.12.10/lib/python3.12/site-packages/ipykernel/kernelbase.py:590> cb=[Task.__wakeup()]>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Done\n",
      "Epoch 2: {'grad_norm': '3.7136', 'loss': '2.0415', 'policy_accuracy': '0.6159', 'policy_loss': '1.0025', 'value_loss': '0.6460'}\n",
      "Testing\n",
      "Epoch 2: {'pip_count_baseline_avg_outcome': '-0.0781'}\n",
      "Epoch 2: {'gnubg_baseline_avg_outcome': '-0.8125'}\n",
      "Temperature: 0.88\n",
      "Collecting self-play games\n",
      "Training\n",
      "Training Done\n",
      "Epoch 3: {'grad_norm': '2.7637', 'loss': '1.9250', 'policy_accuracy': '0.6197', 'policy_loss': '1.0007', 'value_loss': '0.6051'}\n",
      "Temperature: 0.84\n",
      "Collecting self-play games\n",
      "Training\n",
      "Training Done\n",
      "Epoch 4: {'grad_norm': '2.1672', 'loss': '1.8159', 'policy_accuracy': '0.6406', 'policy_loss': '0.9832', 'value_loss': '0.5779'}\n",
      "Testing\n",
      "Epoch 4: {'pip_count_baseline_avg_outcome': '-0.0469'}\n",
      "Epoch 4: {'gnubg_baseline_avg_outcome': '0.4375'}\n",
      "Temperature: 0.8\n",
      "Collecting self-play games\n",
      "Training\n",
      "Training Done\n",
      "Epoch 5: {'grad_norm': '1.8031', 'loss': '1.7868', 'policy_accuracy': '0.6401', 'policy_loss': '0.9973', 'value_loss': '0.5869'}\n",
      "Temperature: 0.76\n",
      "Collecting self-play games\n",
      "Training\n",
      "Training Done\n",
      "Epoch 6: {'grad_norm': '1.7217', 'loss': '1.7572', 'policy_accuracy': '0.6534', 'policy_loss': '0.9891', 'value_loss': '0.6047'}\n",
      "Testing\n",
      "Epoch 6: {'pip_count_baseline_avg_outcome': '-0.4531'}\n"
     ]
    }
   ],
   "source": [
    "# Run training for 20 epochs, evaluate every 2 epochs for frequent feedback\n",
    "output = trainer.train_loop(seed=0, num_epochs=20, eval_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkwFUOlM5j55"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyNzktEqv2pcpe22OSejjXbE",
   "gpuType": "V28",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (bgai)",
   "language": "python",
   "name": "bgai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}