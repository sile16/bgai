{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BGAI Worker - Colab Edition\n",
    "\n",
    "This notebook runs a **game worker** or **eval worker** on Google Colab that connects back to your main training node via Tailscale. Supports both **TPU** and **GPU** runtimes.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "The distributed training system uses **Redis-based coordination** (no Ray required):\n",
    "- Workers connect directly to Redis on the head node\n",
    "- Model weights are synchronized via Redis\n",
    "- Experiences are sent to a Redis replay buffer\n",
    "- Workers auto-register and send heartbeats\n",
    "\n",
    "## Worker Types\n",
    "\n",
    "- **Game Worker**: Generates self-play games using MCTS, sends experiences to replay buffer\n",
    "- **Eval Worker**: Evaluates model against baselines (random, self-play)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Tailscale Auth Key**: Generate a reusable auth key at https://login.tailscale.com/admin/settings/keys\n",
    "2. **Head Node Running**: Your main node should have:\n",
    "   - Tailscale installed and running\n",
    "   - Redis server running (port 6379)\n",
    "   - Coordinator running (`python -m distributed.cli.main coordinator`)\n",
    "3. **Colab Runtime**: Select GPU or TPU (Runtime -> Change runtime type)\n",
    "4. **Colab Secrets**: Add `tailscale-key` and `redis-pass` to Colab secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Fix JAX Version (Required)\n",
    "\n",
    "Colab's default JAX version has a bug. We need to upgrade it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Upgrade JAX first to fix version incompatibility\n",
    "# This must run BEFORE any other imports\n",
    "import os\n",
    "\n",
    "# Detect if we're on TPU or GPU\n",
    "if 'COLAB_TPU_ADDR' in os.environ:\n",
    "    print(\"TPU detected - installing JAX with TPU support...\")\n",
    "    !pip install -q --upgrade jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n",
    "else:\n",
    "    print(\"GPU/CPU detected - installing JAX with CUDA support...\")\n",
    "    !pip install -q --upgrade \"jax[cuda12]\"\n",
    "\n",
    "# Also upgrade optax and flax to compatible versions\n",
    "!pip install -q --upgrade optax flax\n",
    "\n",
    "print(\"\\nJAX upgraded. You may need to restart the runtime if prompted.\")\n",
    "print(\"After restart, skip this cell and continue from the next one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify JAX installation\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Force JAX initialization\n",
    "_ = jnp.ones(1) + 1\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "\n",
    "ACCELERATOR = jax.default_backend()\n",
    "if ACCELERATOR == 'gpu':\n",
    "    !nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\n",
    "elif ACCELERATOR == 'tpu':\n",
    "    print(f\"TPU cores: {len(jax.devices())}\")\n",
    "else:\n",
    "    print(\"WARNING: Running on CPU - this will be slow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Tailscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Tailscale on Colab\n",
    "!curl -fsSL https://tailscale.com/install.sh | sh\n",
    "!pip install -q pysocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Tailscale daemon in userspace mode (required for Colab)\n",
    "import time\n",
    "\n",
    "!pkill tailscaled 2>/dev/null || true\n",
    "!nohup tailscaled --tun=userspace-networking --socks5-server=localhost:1055 --socket=/var/run/tailscale/tailscaled.sock > /dev/null 2>&1 &\n",
    "time.sleep(3)\n",
    "print(\"Tailscale daemon started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Tailscale\n",
    "from google.colab import userdata\n",
    "\n",
    "TAILSCALE_AUTH_KEY = userdata.get('tailscale-key')\n",
    "!sudo tailscale up --authkey={TAILSCALE_AUTH_KEY} --hostname=colab-bgai-worker\n",
    "\n",
    "print(\"\\nColab Tailscale IP:\")\n",
    "!tailscale ip -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Set your head node's Tailscale IP\n",
    "from google.colab import userdata\n",
    "\n",
    "HEAD_NODE_IP = \"100.105.50.111\"  # Your head node's Tailscale IP\n",
    "REDIS_PASSWORD = userdata.get('redis-pass')\n",
    "\n",
    "print(f\"Head Node IP: {HEAD_NODE_IP}\")\n",
    "print(f\"Redis: {HEAD_NODE_IP}:6379\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connectivity to head node\n",
    "!tailscale ping -c 3 {HEAD_NODE_IP}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure SOCKS proxy for Redis connection through Tailscale\n",
    "import socket\n",
    "import socks\n",
    "\n",
    "socks.set_default_proxy(socks.SOCKS5, \"127.0.0.1\", 1055)\n",
    "socket.socket = socks.socksocket\n",
    "print(\"SOCKS proxy configured for Tailscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Redis connectivity\n",
    "!pip install -q redis\n",
    "import redis\n",
    "\n",
    "try:\n",
    "    r = redis.Redis(host=HEAD_NODE_IP, port=6379, password=REDIS_PASSWORD, decode_responses=True)\n",
    "    r.ping()\n",
    "    print(\"Redis connection: OK\")\n",
    "    print(f\"  Model version: {r.get('bgai:model:version') or 'None'}\")\n",
    "    print(f\"  Buffer episodes: {r.llen('bgai:buffer:episodes')}\")\n",
    "except Exception as e:\n",
    "    print(f\"Redis connection FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install remaining dependencies\n",
    "!pip install -q pgx chex redis msgpack msgpack-numpy prometheus_client psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install turbozero\n",
    "!pip install -q git+https://github.com/sile16/turbozero.git@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone bgai repository\n",
    "!git clone https://github.com/sile16/bgai.git /content/bgai 2>/dev/null || (cd /content/bgai && git pull)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/content/bgai')\n",
    "print(\"bgai repository ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worker configuration\n",
    "import uuid\n",
    "\n",
    "# =============================================================================\n",
    "# CHOOSE WORKER TYPE: 'game' or 'eval'\n",
    "# =============================================================================\n",
    "WORKER_TYPE = 'game'  # @param ['game', 'eval']\n",
    "\n",
    "# Common configuration - adjust based on your accelerator's memory\n",
    "# TPU: can use larger batch sizes (32-64)\n",
    "# GPU T4: use 16-32\n",
    "# GPU A100: use 64-128\n",
    "BATCH_SIZE = 16  # @param {type:\"integer\"}\n",
    "NUM_SIMULATIONS = 100  # @param {type:\"integer\"}\n",
    "MAX_NODES = 400  # @param {type:\"integer\"}\n",
    "\n",
    "# Generate unique worker ID\n",
    "WORKER_ID = f\"colab-{WORKER_TYPE}-{str(uuid.uuid4())[:8]}\"\n",
    "\n",
    "# Build config based on worker type\n",
    "if WORKER_TYPE == 'game':\n",
    "    WORKER_CONFIG = {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'num_simulations': NUM_SIMULATIONS,\n",
    "        'max_nodes': MAX_NODES,\n",
    "        'temperature': 1.0,\n",
    "        'max_episode_steps': 500,\n",
    "        'redis_host': HEAD_NODE_IP,\n",
    "        'redis_port': 6379,\n",
    "        'redis_password': REDIS_PASSWORD,\n",
    "        'metrics_port': 9100,\n",
    "    }\n",
    "else:  # eval\n",
    "    WORKER_CONFIG = {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'num_simulations': NUM_SIMULATIONS * 2,  # Eval uses more simulations\n",
    "        'max_nodes': MAX_NODES * 2,\n",
    "        'eval_games': 100,\n",
    "        'eval_interval': 300,\n",
    "        'eval_types': ['random', 'self_play'],  # gnubg not available on Colab\n",
    "        'redis_host': HEAD_NODE_IP,\n",
    "        'redis_port': 6379,\n",
    "        'redis_password': REDIS_PASSWORD,\n",
    "        'metrics_port': 9300,\n",
    "    }\n",
    "\n",
    "print(f\"Worker Type: {WORKER_TYPE.upper()}\")\n",
    "print(f\"Worker ID: {WORKER_ID}\")\n",
    "print(f\"Accelerator: {ACCELERATOR.upper()}\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "for k, v in WORKER_CONFIG.items():\n",
    "    if k != 'redis_password':\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the worker\n",
    "# Note: This imports JAX-dependent modules, so JAX must be initialized first\n",
    "print(f\"Creating {WORKER_TYPE} worker...\")\n",
    "\n",
    "try:\n",
    "    if WORKER_TYPE == 'game':\n",
    "        from distributed.workers.game_worker import GameWorker\n",
    "        worker = GameWorker(config=WORKER_CONFIG, worker_id=WORKER_ID)\n",
    "    else:\n",
    "        from distributed.workers.eval_worker import EvalWorker\n",
    "        worker = EvalWorker(config=WORKER_CONFIG, worker_id=WORKER_ID)\n",
    "    \n",
    "    print(f\"{WORKER_TYPE.title()} worker created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR creating worker: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the worker (runs indefinitely until interrupted)\n",
    "print(f\"Starting {WORKER_TYPE} worker...\")\n",
    "print(\"Press the stop button (or Runtime -> Interrupt) to stop.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    result = worker.run(num_iterations=-1)  # -1 = infinite\n",
    "    print(f\"Worker finished: {result}\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nInterrupted - stopping worker...\")\n",
    "    worker.stop()\n",
    "    print(\"Worker stopped.\")\n",
    "except Exception as e:\n",
    "    print(f\"Worker error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Monitoring (Optional)\n",
    "\n",
    "Run these cells after stopping the worker or in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Redis buffer and cluster status\n",
    "import redis\n",
    "\n",
    "try:\n",
    "    r = redis.Redis(host=HEAD_NODE_IP, port=6379, password=REDIS_PASSWORD, decode_responses=True)\n",
    "    \n",
    "    print(\"Cluster Status:\")\n",
    "    print(f\"  Model version: {r.get('bgai:model:version') or 'None'}\")\n",
    "    print(f\"  Buffer episodes: {r.llen('bgai:buffer:episodes')}\")\n",
    "    \n",
    "    # Check registered workers\n",
    "    worker_keys = r.keys('bgai:worker:*:info')\n",
    "    print(f\"  Registered workers: {len(worker_keys)}\")\n",
    "    for key in worker_keys:\n",
    "        worker_id = key.split(':')[2]\n",
    "        info = r.hgetall(key)\n",
    "        print(f\"    - {worker_id}: {info.get('worker_type', '?')} ({info.get('status', '?')})\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not check status: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the worker gracefully\n",
    "try:\n",
    "    worker.stop()\n",
    "    print(\"Worker stopped and deregistered.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error stopping worker: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disconnect Tailscale (optional)\n",
    "!sudo tailscale down\n",
    "print(\"Tailscale disconnected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### JAX Version Errors\n",
    "- **TypeError with @jit**: Run the JAX upgrade cell first, then restart runtime if prompted\n",
    "- **Import errors**: Make sure you ran the JAX upgrade cell before importing anything\n",
    "\n",
    "### Kernel Crashes\n",
    "- **On worker creation**: Usually means JAX ran out of memory. Reduce `BATCH_SIZE`.\n",
    "- **TPU initialization**: Make sure the JAX initialization cell ran successfully before creating the worker.\n",
    "\n",
    "### Tailscale Issues\n",
    "- **Auth key expired**: Generate a new key at https://login.tailscale.com/admin/settings/keys\n",
    "- **Can't reach head node**: Check that Tailscale is running on both machines\n",
    "\n",
    "### Redis Issues\n",
    "- **Auth failed**: Check the Redis password matches\n",
    "- **Connection refused**: Ensure Redis is bound to 0.0.0.0 or Tailscale IP\n",
    "\n",
    "### TPU/GPU/Memory Issues\n",
    "- **OOM**: Reduce `BATCH_SIZE` in configuration (try 8 or 4)\n",
    "- **No accelerator**: Check Colab runtime type (Runtime -> Change runtime type)\n",
    "\n",
    "### Worker Issues\n",
    "- **Model not found**: The worker will use random weights until training publishes a model\n",
    "- **Coordinator not running**: Start coordinator on head node: `python -m distributed.cli.main coordinator`"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
